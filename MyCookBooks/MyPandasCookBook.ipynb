{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pandas Cookbook  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First a word on filepaths : Absolute vs Relative   \n",
    "\n",
    "- The Absolute path is the full path to some place on your computer.   \n",
    "- The Relative path is the path to some file with respect to your current working directory (PWD).    \n",
    "\n",
    "For example:-\n",
    "\n",
    "Absolute path: C:/users/admin/docs/stuff.txt  <-- use this always, don't be lazy!!!\n",
    "\n",
    "If my PWD is C:/users/admin/, then the relative path to stuff.txt would be: docs/stuff.txt  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading files\r\n",
    "- Warning makign column(s)!! an index, makes them immutable!! "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Big list of Pandas Bugs and errors that will trip you up\r\n",
    "\r\n",
    "1. If you add a column to your data set, make sure you add it even when selecting a df subset of the columns\r\n",
    "- This issue caused no errors when refferencing non-existing columns in df subsets in loop itteration\r\n",
    "e.g \r\n",
    "\r\n",
    "```\r\n",
    "if you add a column : 'nuDataColumn' , make sure to add it to subset\r\n",
    "\r\n",
    "oldDataset = [['columns1','column3']]\r\n",
    "nuDataset = [['columns1','column3','nuDataset']]\r\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "import pandas as pd\r\n",
    "import xlrd\r\n",
    "from datetime import datetime\r\n",
    "\r\n",
    "'''Excel Files'''\r\n",
    "date_cols = ['date_cc']\r\n",
    "df_excel = pd.read_excel(r'C:\\Users\\Burudani\\Documents\\mainPythonFolder_v1\\SpreadsheetFiles\\Coffee_v1.xlsx',\r\n",
    "sheet_name='Coffee')\r\n",
    "# Specifying data types\r\n",
    "df_excel = pd.read_excel(r'C:\\Users\\Burudani\\Documents\\mainPythonFolder_v1\\SpreadsheetFiles\\Coffee_v1.xlsx',\r\n",
    "sheet_name='Coffee',\r\n",
    "dtype = {\"image\": str,\r\n",
    "         \"freq\": float})\r\n",
    "\r\n",
    "\r\n",
    "'''CSV Files'''\r\n",
    "date_cols = ['date_cc'] # Specifying columns to be treated as datetimes, and passing it to the pandas \r\n",
    "df_csv = pd.read_csv (r'C:\\Users\\Burudani\\Documents\\mainPythonFolder_v1\\SpreadsheetFiles\\climate_change.csv',parse_dates=date_cols,\r\n",
    "dtype={\"co2\": float,\r\n",
    "\"relative_temp\": float})\r\n",
    "\r\n",
    "# Specifying index column via column location\r\n",
    "medals = pd.read_csv(r'C:\\Users\\Burudani\\Documents\\mainPythonFolder_v1\\SpreadsheetFiles\\medals_by_country_2016.csv',index_col = 0)  \r\n",
    "\r\n",
    "# Specifying index column via column name\r\n",
    "\r\n",
    "indexColumns = ['ID','Name'] # should n be date columns as this allows you to parse through them easier\r\n",
    "summer2016 = pd.read_csv(r'C:\\Users\\Burudani\\Documents\\mainPythonFolder_v1\\SpreadsheetFiles\\summer2016.csv',index_col = indexColumns)  \r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Print columns as a list\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "import pandas as Pd\r\n",
    "data2 = [['julian', 14], ['3096793G009', 33], ['3096793G9', 14]]\r\n",
    "\r\n",
    "# Create the pandas DataFrame\r\n",
    "df2 = pd.DataFrame(data2, columns = ['Bpn', 'name'])\r\n",
    "print('These are the columns:- \\n', list(df2.columns))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "These are the columns:- \n",
      " ['Bpn', 'name']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find column type"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(df1.column.dtype)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Formatting Dates  \r\n",
    "\r\n",
    "### Common Errors  \r\n",
    "- AttributeError: 'datetime.datetime' object has no attribute 'days' :  for this use  \"day\" instead of \"days\".  Don't confuse this with timedelta objects which does have the attribute \"days\"\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# importing pandas as pd\r\n",
    "import pandas as pd\r\n",
    "  \r\n",
    "# Create the Timestamp object\r\n",
    "# ts = pd.Timestamp(year = 2015,  month = 10, day = 6,\r\n",
    "#            hour = 10, second = 49, tz = 'US/Central')\r\n",
    "ts = pd.Timestamp(year = 2015,  month = 10, day = 6)\r\n",
    "  \r\n",
    "# Print the Timestamp object\r\n",
    "print(ts.date())\r\n",
    "\r\n",
    "\r\n",
    "ts2 =pd.Timestamp(\"1980-01-01\")\r\n",
    "print(ts2.date())\r\n",
    "print(ts2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2015-10-06\n",
      "1980-01-01\n",
      "1980-01-01 00:00:00\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using condition on a dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "# Creating a new Df cleanly using  a condition to get  males, and gymnasts, also specifying  what columns are needed\r\n",
    "\r\n",
    "date_cols = ['Year']\r\n",
    "summer2016 = pd.read_csv(r'C:\\Users\\Burudani\\Documents\\mainPythonFolder_v1\\SpreadsheetFiles\\summer2016.csv',parse_dates=date_cols)\r\n",
    "\r\n",
    "slicedDf = summer2016.loc[(summer2016.Sex == \"M\" ) & (summer2016.Sport == \"Gymnastics\" ),[\"Sex\",\"Sport\"]]\r\n",
    "\r\n",
    "#Reseting the index after obtaining the slice...mainly for ease of viewing\r\n",
    "slicedDf.reset_index(drop=True, inplace = True)\r\n",
    "\r\n",
    "print(slicedDf)\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   Sex       Sport\n",
      "0    M  Gymnastics\n",
      "1    M  Gymnastics\n",
      "2    M  Gymnastics\n",
      "3    M  Gymnastics\n",
      "4    M  Gymnastics\n",
      "5    M  Gymnastics\n",
      "6    M  Gymnastics\n",
      "7    M  Gymnastics\n",
      "8    M  Gymnastics\n",
      "9    M  Gymnastics\n",
      "10   M  Gymnastics\n",
      "11   M  Gymnastics\n",
      "12   M  Gymnastics\n",
      "13   M  Gymnastics\n",
      "14   M  Gymnastics\n",
      "15   M  Gymnastics\n",
      "16   M  Gymnastics\n",
      "17   M  Gymnastics\n",
      "18   M  Gymnastics\n",
      "19   M  Gymnastics\n",
      "20   M  Gymnastics\n",
      "21   M  Gymnastics\n",
      "22   M  Gymnastics\n",
      "23   M  Gymnastics\n",
      "24   M  Gymnastics\n",
      "25   M  Gymnastics\n",
      "26   M  Gymnastics\n",
      "27   M  Gymnastics\n",
      "28   M  Gymnastics\n",
      "29   M  Gymnastics\n",
      "30   M  Gymnastics\n",
      "31   M  Gymnastics\n",
      "32   M  Gymnastics\n",
      "33   M  Gymnastics\n",
      "34   M  Gymnastics\n",
      "35   M  Gymnastics\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Applying a date condition to a dataframe\r\n",
    "\r\n",
    "- Workign with dates can ve EXTREMELY tricky, and is often one of if not the most trickiest prt to deal with when processing dataframes\r\n",
    "- These are the best practices for when dealing with dates in dataframes :-  \r\n",
    "    1. make sure ALL date columns are converted to and are recognized as dates by using the \"parse dates function\" when creating the DF\r\n",
    "    2. Ensure that all dates that are to be used in the condition are in PROPER -US Timestamp format i.e YYYY-MM-DD \r\n",
    "    "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "# US Timestamp format example\r\n",
    "import pandas as pd \r\n",
    "exampleFormat = pd.Timestamp(year=2017, month=1, day=26, hour=12)\r\n",
    "print(exampleFormat)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2017-01-26 12:00:00\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "#Parsing dates -  letting python know the date column is made up of \"actual dates\"\r\n",
    "date_cols =  ['date_cc']\r\n",
    "df_climateChange = pd.read_csv (r'C:\\Users\\Burudani\\Documents\\mainPythonFolder_v1\\SpreadsheetFiles\\climate_change.csv',\r\n",
    "parse_dates=date_cols)\r\n",
    "\r\n",
    "#applying a date condition to slice the data and provide a new dataframe\r\n",
    "df_eighties = df_climateChange[(df_climateChange.date_cc > '1980-01-06') & (df_climateChange.date_cc <= '1989-12-31')]\r\n",
    "\r\n",
    "#Reseting the index after obtaining the slice...mainly for ease of viewing\r\n",
    "df_eighties.reset_index(drop=True, inplace = True)\r\n",
    "\r\n",
    "print(df_eighties)\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       date_cc     co2  relative_temp\n",
      "0   1980-02-06  338.34           0.42\n",
      "1   1980-03-06  340.01           0.29\n",
      "2   1980-04-06  340.93           0.32\n",
      "3   1980-05-06  341.48           0.34\n",
      "4   1980-06-06  341.33           0.16\n",
      "..         ...     ...            ...\n",
      "114 1989-08-06  351.81           0.36\n",
      "115 1989-09-06  350.05           0.37\n",
      "116 1989-10-06  350.25           0.32\n",
      "117 1989-11-06  351.49           0.21\n",
      "118 1989-12-06  352.85           0.37\n",
      "\n",
      "[119 rows x 3 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Assigning and Re-assigning dataframes  \r\n",
    "\r\n",
    "- Use the \"in place\" command e.g \r\n",
    "- Otherwise you may have to re-assign the dataframe to avoid duplication issues"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deleting(dropping) and adding columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "df = df.drop(df.columns[[0, 1, 3]], axis=1)  # df.columns is zero-based pd.Index\r\n",
    "\r\n",
    "\r\n",
    "'''This can be done more elegantly below :- '''\r\n",
    "\r\n",
    "columns = ['Col1', 'Col2', ...]\r\n",
    "df.drop(columns, inplace=True, axis=1)\r\n",
    "\r\n",
    "# or using indices\r\n",
    "\r\n",
    "columns = [0,3, ...]\r\n",
    "df.drop(columns, inplace=True, axis=1)\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using groupby\r\n",
    "-  Note: groupby creates a groupby object and NOT a new dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "\r\n",
    "df = pd.read_csv(r\"SpreadsheetFiles\\nba.csv\")\r\n",
    "# First grouping based on \"Team\"\r\n",
    "# Within each team we are grouping based on \"Position\"\r\n",
    "gkk = df.groupby(['Team', 'Position'])\r\n",
    "  \r\n",
    "# Print the first value in each group\r\n",
    "print(gkk)\r\n",
    "#gkk.first()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000299E2C24EE0>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import re\r\n",
    " \r\n",
    "# initialize list of lists\r\n",
    "#data1 = [['john', 14],['3096793G9', 'dd'], ['nick', 15], ['juli', 14]]\r\n",
    "data1 = [['john', 14],['3096793G9', 33], ['nick', 15], ['juli', 14]] \r\n",
    "# Create the pandas DataFrame\r\n",
    "df1 = pd.DataFrame(data1, columns = ['Dpn', 'name'])\r\n",
    " \r\n",
    "# initialize list of lists\r\n",
    "#data2 = [['jilian', 14], ['3096793G009', 'bb'], ['barbra', 14]]\r\n",
    "data2 = [['jilian', 14], ['3096793G009', 33], ['3096793G9', 14]]\r\n",
    " \r\n",
    "# Create the pandas DataFrame\r\n",
    "df2 = pd.DataFrame(data2, columns = ['Bpn', 'name'])\r\n",
    "\r\n",
    "\r\n",
    "#easy way to print columns\r\n",
    "print('These are the columns:- \\n', list(df2.columns))\r\n",
    "\r\n",
    "# print dataframe.\r\n",
    "#print(df2)\r\n",
    "\r\n",
    "\r\n",
    "print('-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-')\r\n",
    "\r\n",
    "for index2, row2 in df2.iterrows(): #rep\r\n",
    "    for index1, row1 in df1.iterrows(): #dc  dp is goign to change\r\n",
    "        #if row1['Dpn'].re.match('\\w[0]{0,2}\\d')== row2['Bpn'] :\r\n",
    "      \r\n",
    "        testword = (row1['Dpn'][:7])+'\\w[0]{0,2}\\d'\r\n",
    "        #print(testword, 'testing match with',row2['Bpn'] )\r\n",
    "        jimmy = re.match((row1['Dpn'][:7])+'\\w[0]{0,2}\\d',row2['Bpn'])\r\n",
    "        #print('*******************************************')\r\n",
    "     \r\n",
    "        #print(row1['Dpn'],row2['Bpn'])\r\n",
    "        if jimmy:\r\n",
    "            #print('Match found',jimmy.group(0))\r\n",
    "            matchTester = 'Match Exists'\r\n",
    "        else:\r\n",
    "            matchTester = 'Match Does not Exists'\r\n",
    "        print(testword, 'testing match with',row2['Bpn'],matchTester )\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\r\n",
    " \r\n",
    "\r\n",
    "df = pd.read_excel(r'C:\\Users\\Burudani\\Documents\\testerDoc.xlsx',\r\n",
    "sheet_name='Sheet1')\r\n",
    "# initialize list of lists\r\n",
    "\r\n",
    "#df[df.columns[0:4]].fillna(value=0, inplace=True)\r\n",
    "\r\n",
    "#gapminder[gapminder.columns[0:2]].head()\r\n",
    "\r\n",
    "str_cols = ['Name','oname', 'cname','dname','Lname','Age']\r\n",
    "columns2drop = ['dname', 'Lname']\r\n",
    " \r\n",
    "print(str_cols)\r\n",
    "df[str_cols] = df[str_cols].fillna('')\r\n",
    "\r\n",
    "#df.oname.fillna(value = 'N/A',inplace = True)\r\n",
    "\r\n",
    "# def concatColumns(stringColumnList):\r\n",
    "#     nucombinedColumn = []\r\n",
    "#     for column in stringColumnList:\r\n",
    "#         nucombinedColumn.append('df['+'\"'+column +'\"'+']'+ ';')\r\n",
    "#     print (nucombinedColumn)\r\n",
    "\r\n",
    "# concatColumns(str_cols)\r\n",
    " \r\n",
    "# for columns str_cols:\r\n",
    "#     df['Nucolumn'] = \r\n",
    "\r\n",
    "\r\n",
    "df['Nucolumn'] = df['Name'] +';'\\\r\n",
    "+ df['oname']+';'\\\r\n",
    "+ df['cname']+';'\\\r\n",
    "+ df['dname']+';'\\\r\n",
    "+ df['Lname']+';'\r\n",
    "\r\n",
    "#TODO strip spaces from final column output hint*** USE REGEX\r\n",
    "print(df)\r\n",
    "#df.Nucolumn = df.Nucolumn.apply(lambda x : (x.replace(';{1,3}','x',False)))\r\n",
    "df.Nucolumn = df.Nucolumn.replace(to_replace=';{1,9}|^;{1}', value=';', regex=True)\r\n",
    "df.Nucolumn = df.Nucolumn.replace(to_replace=';{1,9}|^;{1}', value=';', regex=True)\r\n",
    "df.Nucolumn = df.Nucolumn.replace(to_replace='^;{1}', value='', regex=True)\r\n",
    "\r\n",
    "df.drop(columns = columns2drop, inplace = True)\r\n",
    "\r\n",
    "print(df)\r\n",
    "#print(newdf)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Name', 'oname', 'cname', 'dname', 'Lname', 'Age']\n",
      "   Name     oname    cname dname      Lname   Age                Nucolumn\n",
      "0   tom     james  bucanon                   10.0    tom;james;bucanon;;;\n",
      "1  nick             cbambe            harry          nick;;cbambe;;harry;\n",
      "2        jumwlale                 belafonte  14.0  ;jumwlale;;;belafonte;\n",
      "   Name     oname    cname   Age             Nucolumn\n",
      "0   tom     james  bucanon  10.0   tom;james;bucanon;\n",
      "1  nick             cbambe         nick;cbambe;harry;\n",
      "2        jumwlale           14.0  jumwlale;belafonte;\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import plotly.express as px\r\n",
    "\r\n",
    "# data\r\n",
    "df = pd.DataFrame({'A': {0: 34, 1: 34, 2: 34, 3: 34, 4: 56, 5: 56, 6: 78},\r\n",
    "                     'B': {0: 34, 1: 223, 2: 56, 3: 86, 4: 86, 5: 43, 6: 34},\r\n",
    "                     'C': {0: -12, 1: -12, 2: -12, 3: -12, 4: -12, 5: -12, 6: -12}})\r\n",
    "\r\n",
    "colors = px.colors.qualitative.T10\r\n",
    "\r\n",
    "# plotly\r\n",
    "fig = px.bar(df, \r\n",
    "             x = df.index,\r\n",
    "             y = [c for c in df.columns],\r\n",
    "             template = 'plotly_dark',\r\n",
    "             color_discrete_sequence = colors,\r\n",
    "             title = 'Stacked bar chart using px.bar()', \r\n",
    "             )\r\n",
    "\r\n",
    "fig.show()\r\n",
    "print('hello world')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# imports\r\n",
    "import plotly\r\n",
    "import cufflinks as cf\r\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "# setup\r\n",
    "init_notebook_mode(connected=True)\r\n",
    "np.random.seed(123)\r\n",
    "cf.set_config_file(theme='pearl')\r\n",
    "\r\n",
    "# qtconsole for debugging\r\n",
    "#%qtconsole --style vim #src# https://qtconsole.readthedocs.io/en/stable/\r\n",
    "\r\n",
    "# Random data using cufflinks\r\n",
    "df = cf.datagen.lines()\r\n",
    "df = df[['UUN.XY', 'MJF.XV', 'XBB.AO']].head(50)\r\n",
    "df=np.abs(df)\r\n",
    "\r\n",
    "# make figure\r\n",
    "fig = df.iplot(asFigure=True, kind='bar', barmode = 'stack',\r\n",
    "               xTitle='Dates',yTitle='Returns',title='Returns')\r\n",
    "\r\n",
    "# plot figure\r\n",
    "iplot(fig)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = [['Ravi',21,67],['Kiran',24,61],['Anita',18,46],['Smita',20,78],['Sunil',17,90]]\r\n",
    "df = pd.DataFrame(data,columns = ['name','age','marks'],dtype = float)\r\n",
    "trace = go.Bar(x = df.name, y = df.marks)\r\n",
    "fig = go.Figure(data = [trace])\r\n",
    "iplot(fig)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = [['Ravi',21,67],['Kiran',24,61],['Anita',18,46],['Smita',20,78],['Sunil',17,90]]\r\n",
    "df = pd.DataFrame(data,columns = ['name','age','marks'],dtype = float)\r\n",
    "df.iplot(kind = 'bar', x = 'name', y = 'marks')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib\r\n",
    "\r\n",
    "#Bring in original Data sheet\r\n",
    "df1 = pd.read_excel(r\"C:\\Users\\Burudani\\Documents\\Finance_Trending\\Checking_Jan1st2021_March10th2021.xlsx\")  \r\n",
    "#df1.columns = ['Date','Amount','Description']\r\n",
    "print(df1.head())\r\n",
    "\r\n",
    "\r\n",
    "# Bring in the excell sheet that you will use to create the final column\r\n",
    "df2 = pd.read_excel(r\"C:\\Users\\Burudani\\Documents\\Finance_Trending\\bank_amount_guide.xlsx\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#df = df.assign(model2='Expenses')\r\n",
    "\r\n",
    "#df.loc[:,'model2'] = str('Expenses')\r\n",
    "\r\n",
    "\r\n",
    "#df['model2'] = 'Expenditure'\r\n",
    "checkList = [\"BANANA REPUBLIC PAYMENT\",\"CHECK\",\"DE POST PAID DET BILL PAY \",\"GEICO PREM COLL \",\"JPMorgan Chase Ext Trnsfr\",\"CHASE CREDIT CRD AUTOPAY \",\"LOCKHEED MARTIN DIR DEP\",\"MACYS PAYMENT\",\"MONEY TRANSFER\",\"NELNET LOAN\",\"NORDSTROM PAYMENT\",\"OVERDRAFT FEE\",\"PAYPAL INST XFER\",\"Amazon Digit\",\"Amazon web service\",\"Amazon Prime\",\"wal-mart\",\"tom thumb\",\"7-eleven\",\"aero café\",\"goody goody\",\"wave\",\"txtag\",\"Prime Video\",\"cash app\",\"mcdonald\",\"cortland\",\"apple\",\"35413\",\"uber eats\",\"uber\",\"netflix\",\"at&t\",\"Linux Academy\",\"medium\",\"hour fitness\",\"Zelle from\"]\r\n",
    "checkListUppercase = [x.upper() for x in checkList]\r\n",
    "#if(row.make1.upper() in checkListUppercase):\r\n",
    "\r\n",
    "def NameReplacer(row):\r\n",
    "    '''This Function replaces the long version of the transactional data with a short form version of it'''\r\n",
    "    \r\n",
    "    for item in checkListUppercase:\r\n",
    "        if(item in row.Description.upper()):\r\n",
    "\r\n",
    "            return item\r\n",
    "\r\n",
    "\r\n",
    "df1.loc[:, 'Transaction'] = df1.apply(NameReplacer, axis = 1)\r\n",
    "\r\n",
    "df1.Transaction.fillna(value=np.nan, inplace=True)   # replaces None values with NaN values\r\n",
    "\r\n",
    "df1['Transaction'] = df1['Transaction'].fillna('EXPENDITURE')  # this allows you to now replace the NaN values with anything you want\r\n",
    "#df['modelchecker'].replace(NaN, \"\", inplace=True)\r\n",
    "\r\n",
    "#df['Match_Tester'] = df.apply(lambda errorDetector : df, axis = 1)\r\n",
    "print(df1)\r\n",
    "\r\n",
    "#df1.groupby(['Transaction']).sum()\r\n",
    "\r\n",
    "df1=df1.groupby([(df1.index.Transaction)]).sum()\r\n",
    "df2 = df1.drop(['index','Description'], axis = 1)\r\n",
    "\r\n",
    "df2.to_excel(r\"C:\\Users\\Burudani\\Documents\\Finance_Trending\\Checking_Jan1st2021_March10th2021_results3.xlsx\", index = False)\r\n",
    "\r\n",
    "df1.to_csv(r\"C:\\Users\\Burudani\\Documents\\Finance_Trending\\Checking_Jan1st2021_March10th2021_results4.xlsx\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "106f8dd8e7b9f8bf7b5c7f9387976efaa64fd1db7ebf679a5786be21993f005a"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('rwakiPythonEnv': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}